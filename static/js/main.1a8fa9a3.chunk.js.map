{"version":3,"sources":["components/network/DisplayNetwork.tsx","convts/activations/activations.ts","convts/math/math.ts","convts/layer/ActivationLayer.ts","convts/weight/weight.ts","convts/layer/ConnectedLayer.ts","convts/loss/loss.ts","convts/log/Logger.ts","convts/network/Network.ts","convts/recorder/NeuronListener.ts","components/network/Neuron.tsx","components/network/NeuralRenderer.tsx","App.tsx","convts/network/networks.ts","reportWebVitals.ts","index.tsx"],"names":["DisplayLayer","layer","className","name","getInputSize","getOutputSize","Layers","network","layers","map","l","i","DisplayNetwork","LeakyRelu","input","i1","i2","LeakyReluPrime","dot","a","b","length","b1","b2","Array","from","keys","_","j","reduce","acc","v2","a1","filter","n","isNaN","q","multiply","Error","subtract","transpose","array","columnIndex","row","ActivationLayer","index","activation","activationPrime","neuronListener","output","this","recordNeurons","layerName","result","inputSize","outputSize","outputError","learningRate","createRandomWeights","dim0","dim1","Math","random","ConnectedLayer","weight","bias","t","add","inputError","weightError","Mse","loss","expected","predicted","count","x1","x2","pow","v","acc2","lossPrime","divide","logger","require","Network","data","forwardPropagate","trainingData","categories","epochs","lastEpochError","epoch","error","x","debug","backPropagate","info","backPropagation","forwardPropagation","NeuronListener","callback","record","lastUpdate","Date","now","Neuron","probability","toFixed","LayerSection","neuron","nn","NeuralRenderer","Object","values","App","useState","setLastUpdate","ii","console","log","create","createSimpleNetwork","undefined","setLastEpochError","onClick","fit","startRecording","predict","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"oNAIMA,EAAe,SAAC,GAAiC,IAA/BC,EAA8B,EAA9BA,MACtB,OACE,8BACE,sBACEC,UACE,6FAFJ,UAKGD,EAAME,OAAQ,IACdF,EAAMG,gBAAkBH,EAAMI,gBAA9B,YACQJ,EAAMG,eADd,aACiCH,EAAMI,gBADvC,KAEG,SAMNC,EAAS,SAAC,GAAuC,IAArCC,EAAoC,EAApCA,QAChB,OACE,oCACE,oBAAIL,UAAW,WAAf,oBACCK,EAAQC,OAAOC,KAAI,SAACC,EAAGC,GAAJ,OAClB,cAAC,EAAD,CAAiCV,MAAOS,GAAxC,gBAA4BC,WAcrBC,EARQ,SAAC,GAAuC,IAArCL,EAAoC,EAApCA,QACxB,OACE,8BACE,cAAC,EAAD,CAAQA,QAASA,OCpBVM,EAAwB,SAACC,GAClC,OAAOA,EAAML,KAAI,SAACM,GAAD,OAAQA,EAAGN,KAAI,SAACO,GAC7B,OAAOA,EAAK,EAAIA,EAAU,IAALA,SAIhBC,EAA6B,SAACH,GACvC,OAAOA,EAAML,KAAI,SAACM,GAAD,OAAQA,EAAGN,KAAI,SAACO,GAC7B,OAAOA,EAAK,EAAI,EAAI,W,cCtBfE,EAAM,SAACC,EAAeC,GAGjC,OAAiB,IAAbD,EAAEE,QAAgC,IAAhBF,EAAE,GAAGE,QAA6B,IAAbD,EAAEC,OACpCD,EAAEX,KAAI,SAACa,GAAD,OAAQA,EAAGb,KAAI,SAACc,GAAD,OAAQA,EAAKJ,EAAE,GAAG,SAG/B,IAAbA,EAAEE,QAAgBF,EAAE,GAAGE,OAAS,GAAKD,EAAEC,SAAWF,EAAE,GAAGE,OAClD,CAACG,MAAMC,KAAKD,MAAMJ,EAAE,GAAGC,QAAQK,QAAQjB,KAAI,SAACkB,EAAGhB,GACpD,OAAOQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GAAJ,OAAUT,EAAE,GAAGS,GAAKR,EAAEQ,GAAGjB,MAAIkB,QAAO,SAACC,EAAIC,GAAL,OAAYD,EAAMC,IAAI,OAK1D,IAAhBZ,EAAE,GAAGE,QAA6B,IAAbD,EAAEC,OAClBF,EAAEV,KAAI,SAACuB,EAAIjB,GAChB,OAAOK,EAAE,GAAGX,KAAI,SAACkB,EAAGX,GAClB,OAAOG,EAAEJ,GAAI,GAAKK,EAAE,GAAGJ,MACtBiB,QAAO,SAACC,GAAD,OAAQC,MAAMD,SAIrBf,EAAEV,KAAI,SAACuB,EAAIjB,GAChB,OAAOI,EAAEV,KAAI,SAACkB,EAAGX,GACf,OAAOQ,MAAMC,KAAKD,MAAMQ,EAAGX,QAAQK,QAAQG,QAAO,SAACC,EAAKM,GAEtD,OAAON,EAAMX,EAAEJ,GAAIqB,GAAKhB,EAAEgB,GAAGpB,KAC5B,MAGFiB,QAAO,SAACC,GAAD,OAAQC,MAAMD,UAGfG,EAAW,SAAClB,EAAeC,GACtC,GAAiB,kBAANA,EACT,OAAOD,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OAAUQ,EAAER,GAAGF,KAAI,SAACkB,EAAGC,GAAJ,OAAUT,EAAER,GAAGiB,GAAKR,QAEtD,GAAID,EAAEE,SAAWD,EAAEC,OACjB,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAET,GAAGiB,SAGnB,GAAiB,IAAbT,EAAEE,OACX,OAAOD,EAAEX,KAAI,SAACkB,EAAGhB,GAAJ,OACbS,EAAE,GAAGX,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAE,GAAGS,GAAKR,EAAET,GAAGiB,SAGnB,GAAiB,IAAbR,EAAEC,OACX,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACbQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAE,GAAGQ,SAK5B,MAAMU,MAAM,8BAAD,OAA+BnB,EAA/B,cAAsCC,KAsDtCmB,EAAW,SAACpB,EAAeC,GACtC,GAAID,EAAEE,SAAWD,EAAEC,OACjB,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbT,EAAEE,OACX,OAAOD,EAAEX,KAAI,SAACkB,EAAGhB,GAAJ,OACXS,EAAE,GAAGX,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAE,GAAGS,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbR,EAAEC,OACX,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAE,GAAGQ,SAK5B,MAAMU,MAAM,8BAAD,OAA+BnB,EAA/B,cAAsCC,KAUtCoB,EAAY,SAACC,GACxB,OAAOA,EAAM,GAAGhC,KAAI,SAACkB,EAAGe,GAAJ,OAAoBD,EAAMhC,KAAI,SAACkC,GAAD,OAASA,EAAID,UCnGlDE,E,WAjCb,WAAYC,EAAeC,EAAwBC,EAA6BC,GAAiC,yBANjHF,gBAMgH,OALhHC,qBAKgH,OAJhHjC,MAAoB,GAI4F,KAHhHmC,OAAsB,GAG0F,KAFhHJ,WAEgH,OADhHG,oBACgH,EAC9GE,KAAKJ,WAAaA,EAClBI,KAAKH,gBAAkBA,EACvBG,KAAKL,MAAQA,EACbK,KAAKF,eAAiBA,E,wCAGxB,WACE,MAAO,e,0BAGT,c,2BAIA,c,gCAIA,SAAmBlC,GAMjB,OALAoC,KAAKpC,MAAQA,EACboC,KAAKD,OAASC,KAAKJ,WAAWhC,GAC1BoC,KAAKF,gBACPE,KAAKF,eAAeG,cAAcD,KAAKL,MAAO,CAACO,UAAW,aAAcC,OAAQH,KAAKD,OAAQK,UAAWxC,EAAM,GAAGO,OAAQkC,WAAYL,KAAKD,OAAO,GAAG5B,SAE/I6B,KAAKD,S,6BAEd,SAAgBO,EAAyBC,GAEvC,OAAOpB,EAASa,KAAKH,gBAAgBG,KAAKpC,OAAQ0C,O,KCnCzCE,EAAsB,SAACC,EAAcC,GAChD,OAAOpC,MAAMC,KAAKD,MAAMmC,GAAMjC,QAAQjB,KAAI,SAACkB,GACzC,OAAOH,MAAMC,KAAKD,MAAMoC,GAAMlC,QAAQjB,KAAI,SAACkB,GACzC,OAAOkC,KAAKC,SAAW,UC6CdC,E,WAxCb,WAAYlB,EAAeS,EAAmBC,EAAoBP,GAAkC,yBAPpGgB,YAOmG,OANnGC,UAMmG,OALnGnD,MAAoB,GAK+E,KAJnGwC,eAImG,OAHnGC,gBAGmG,OAFnGV,WAEmG,OADnGG,oBACmG,EACjGE,KAAKL,MAAQA,EACbK,KAAKI,UAAYA,EACjBJ,KAAKK,WAAaA,EAClBL,KAAKc,OAASN,EAAoBJ,EAAWC,GAC7CL,KAAKe,KAAOP,EAAoB,EAAGH,GACnCL,KAAKF,eAAiBA,E,gDAGxB,WACE,OAAOE,KAAKI,Y,2BAGd,WACE,OAAOJ,KAAKK,a,kBAGd,WACE,MAAO,c,gCAGT,SAAmBzC,GACjBoC,KAAKpC,MAAQA,EACb,IAAMoD,EHmDS,SAAC/C,EAAeC,GACjC,GAAID,EAAEE,SAAWD,EAAEC,OACjB,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbT,EAAEE,OACX,OAAOD,EAAEX,KAAI,SAACkB,EAAGhB,GAAJ,OACXS,EAAE,GAAGX,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAE,GAAGS,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbR,EAAEC,OACX,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAE,GAAGQ,SAK5B,MAAMU,MAAM,8BAAD,OAA+BnB,EAA/B,cAAsCC,IGxErC+C,CAAIjD,EAAIJ,EAAOoC,KAAKc,QAASd,KAAKe,MAI5C,OAHIf,KAAKF,gBACPE,KAAKF,eAAeG,cAAcD,KAAKL,MAAO,CAACO,UAAW,YAAaC,OAAQa,EAAGZ,UAAWJ,KAAKI,UAAWC,WAAYL,KAAKK,aAEzHW,I,6BAET,SAAgBV,EAAyBC,GACvC,IAAMW,EAAalD,EAAIsC,EAAahB,EAAUU,KAAKc,SAC7CK,EAAcnD,EAAIsB,EAAUU,KAAKpC,OAAQ0C,GAK/C,OAHAN,KAAKc,OAASzB,EAASW,KAAKc,OAAQ3B,EAASgC,EAAaZ,IAC1DP,KAAKe,KAAO1B,EAASW,KAAKe,KAAM5B,EAASmB,EAAaC,IAE/CW,M,KCLEE,EAAY,CACrBC,KApC0C,SAC5CC,EACAC,GAEA,IAAIC,EAAQ,EAgBZ,OAfcnC,EAASiC,EAAUC,GAC9BhE,KAAI,SAACkE,GACJ,OAAOA,EAAGlE,KAAI,SAACmE,GAEb,OADAF,GAAS,EACFb,KAAKgB,IAAID,EAAI,SAGvB/C,QAAO,SAACC,EAAKgD,GACZ,OACEhD,EACAgD,EAAEjD,QAAO,SAACkD,EAAMhD,GACd,OAAOgD,EAAOhD,IACb,KAEJ,GACU2C,GAiBbM,UAV4C,SAC9CR,EACAC,GAEA,IAAIC,EAAsBF,EAPjB3C,QAAO,SAACC,EAAKgD,GAAN,OAAYhD,EAAMgD,EAAEzD,SAAQ,GAQ5C,OAAOgB,EJmBa,SAAClB,EAAeC,GACpC,GAAiB,kBAANA,EACT,OAAOD,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OAAUQ,EAAER,GAAGF,KAAI,SAACkB,EAAGC,GAAJ,OAAUT,EAAER,GAAGiB,GAAKR,QAEtD,GAAID,EAAEE,SAAWD,EAAEC,OACjB,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbT,EAAEE,OACX,OAAOD,EAAEX,KAAI,SAACkB,EAAGhB,GAAJ,OACXS,EAAE,GAAGX,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAE,GAAGS,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbR,EAAEC,OACX,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAE,GAAGQ,SAK5B,MAAMU,MAAM,8BAAD,OAA+BnB,EAA/B,cAAsCC,II3CjC6D,CAAO1C,EAASkC,EAAWD,GAAWE,GAAQ,KC1CnDQ,EAASC,EAAQ,GAARA,GCkEPC,E,WAxDb,WAAoB5E,EAAiB+D,GAAa,yBAHlD/D,YAGiD,OAFjD+D,UAEiD,OADjDd,aAAuB,GAErBP,KAAK1C,OAASA,EACd0C,KAAKqB,KAAOA,E,2CAOd,SAAec,GACb,OAAOnC,KAAKoC,iBAAiBD,K,iBAG/B,SACEE,EACAC,EACAC,GAGA,IAFC,IAAD,OACIC,GAAkB,EACbC,EAAQ,EAAGA,GAASF,EAAQE,IAAS,CAC5C,IAUMC,EAVML,EACT9E,KAAI,SAACoF,EAAGlF,GACP,IAAMsC,EAAS,EAAKqC,iBAAiBO,GAGrC,OAFAX,EAAOY,MAAM,CAAC,SAAYN,EAAW7E,GAAI,UAAasC,IACtD,EAAK8C,cAAcP,EAAW7E,GAAIsC,GAC3B,EAAKsB,KAAKA,KAAKiB,EAAW7E,GAAIsC,MAEtCpB,QAAO,SAACC,EAAKgD,GAAN,OAAYhD,EAAMgD,IAAG,GAGXS,EAAalE,OACjC6D,EAAOc,KAAP,gBACWL,EADX,YACoBF,EADpB,kBACoCG,IAEpCF,EAAeE,EAEjB,OAAOF,I,2BAGT,SAAsBlB,EAAsBC,GAC1C,IAAImB,EAAQ1C,KAAKqB,KAAKS,UAAUR,EAAUC,GAC1CS,EAAOY,MAAM,CAAC,cAAeF,IAC7B,IAAK,IAAIjF,EAAIuC,KAAK1C,OAAOa,OAAS,EAAGV,GAAK,EAAGA,IAC3CiF,EAAQ1C,KAAK1C,OAAOG,GAAGsF,gBAAgBL,EAAO1C,KAAKO,gB,8BAIvD,SAAyB4B,GACvB,OAAOnC,KAAK1C,OAAOqB,QAAO,SAACoB,EAAQhD,GACjC,OAAOA,EAAMiG,mBAAmBjD,KAC/BoC,M,qBA7CL,SAAqB7E,EAAiB+D,GACpC,OAAO,IAAIa,EAAQ5E,EAAQ+D,O,KCRlB4B,EAAb,WAOI,WAAYC,GAAgD,yBAL5DA,cAK2D,OAJ3DC,QAAkB,EAIyC,KAH3DC,WAAqBC,KAAKC,MAGiC,KAF3DnD,OAAsC,GAGpCH,KAAKkD,SAAWA,EARtB,kDAWI,WACIlD,KAAKmD,QAAS,IAZtB,2BAeI,WACInD,KAAKmD,QAAS,IAhBtB,2BAmBI,SAAcxD,EAAe/B,GACrBoC,KAAKmD,SACLnD,KAAKoD,WAAaC,KAAKC,MACvBtD,KAAKkD,SAASvD,EAAO/B,GACrBoC,KAAKG,OAAL,UAAeR,IAAW/B,OAvBtC,KCMe2F,EAZA,SAAC,GAA8C,IAA5CC,EAA2C,EAA3CA,YAChB,OACE,qBACExG,UAAS,yDACPwG,EAAc,GAAM,cAAgB,cAD7B,8CADX,SAKGA,EAAYC,QAAQ,MCFrBC,EAAe,SAAC,GAA0C,IAAxCC,EAAuC,EAAvCA,OACtB,OACE,qBAAK3G,UAAW,iDAAhB,SACE,sBAAKA,UAAW,oBAAhB,UACI,sBAAKA,UAAW,YAAhB,UACF,qBAAKA,UAAW,UAAhB,SAA4B2G,EAAOzD,YACnC,sBAAKlD,UAAW,kBAAhB,yBAAgD2G,EAAOvD,aACvD,sBAAKpD,UAAW,mBAAhB,0BAAkD2G,EAAOtD,iBAEzD,qBAAMrD,UAAW,sCAAjB,SACG2G,EAAOxD,OAAO,GAAG5C,KAAI,SAACqG,GAAD,OACpB,cAAC,EAAD,CAAQJ,YAAaI,eA4BlBC,EApBQ,SAAC,GAMlB,EALJT,WAKK,IAJLtD,EAII,EAJJA,eAKA,OACE,sBAAK9C,UAAU,6BAAf,UACE,oBAAIA,UAAU,wCAAd,mCAIC8G,OAAOC,OAAOjE,EAAeK,QAAQ5C,KAAI,SAACyB,GAAD,OACxC,cAAC,EAAD,CAAc2E,OAAQ3E,WCsDfgF,MAhFf,WAAgB,IAAD,EACuBC,mBAASZ,KAAKC,OADrC,mBACNF,EADM,KACMc,EADN,OAE+BD,mBAC1C,IAAIhB,GAAe,SAACxF,EAAG0G,GAAJ,OAAWC,QAAQC,IAAIF,OAH/B,mBAENrE,EAFM,aAKiBmE,mBCXG,SAACnE,GAChC,OAAOoC,EAAQoC,OACX,CACI,IAAIzD,EAAe,EAAG,EAAE,EAAGf,GAC3B,IAAIJ,EAAgB,EAAG/B,EAAUI,EAAgB+B,GACjD,IAAIe,EAAe,EAAG,EAAE,EAAGf,GAC3B,IAAIJ,EAAgB,EAAG/B,EAAUI,EAAgB+B,IAErDsB,GDIJmD,CAAoBzE,KANT,mBAKNzC,EALM,aAQ+B4G,wBAC1CO,IATW,mBAQNhC,EARM,KAQUiC,EARV,KAWPpC,EAAe,CAAC,CAAC,CAAC,EAAG,IAAK,CAAC,CAAC,EAAG,IAAK,CAAC,CAAC,EAAG,IAAK,CAAC,CAAC,EAAG,KACnDC,EAAa,CAAC,CAAC,CAAC,IAAK,CAAC,CAAC,IAAK,CAAC,CAAC,IAAK,CAAC,CAAC,KAE3C,OACE,qBAAKtF,UAAU,sCAAf,SACE,iCACE,cAAC,EAAD,CAAgBK,QAASA,IACzB,wBACEqH,QAAS,WACPD,EAAkBpH,EAAQsH,IAAItC,EAAcC,EAAY,MACxDxC,EAAe8E,kBAEjB5H,UAAU,4EALZ,8BASCwF,GAAkB,yDAA4BA,KAC9CA,GACC,mBACEkC,QAAS,WACPrH,EAAQwH,QAAQ,CAAC,CAAC,EAAG,KACrBX,EAAcpE,EAAesD,aAHjC,yBASDZ,GACC,mBACEkC,QAAS,WACPrH,EAAQwH,QAAQ,CAAC,CAAC,EAAG,KACrBX,EAAcpE,EAAesD,aAHjC,yBASDZ,GACC,mBACEkC,QAAS,WACPrH,EAAQwH,QAAQ,CAAC,CAAC,EAAG,KACrBX,EAAcpE,EAAesD,aAHjC,yBASDZ,GACC,mBACEkC,QAAS,WACPrH,EAAQwH,QAAQ,CAAC,CAAC,EAAG,KACrBX,EAAcpE,EAAesD,aAHjC,yBASF,cAAC,EAAD,CACEA,WAAYA,EACZtD,eAAgBA,UEtEXgF,EAZS,SAACC,GACnBA,GAAeA,aAAuBC,UACxC,6BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCHdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.1a8fa9a3.chunk.js","sourcesContent":["import React from \"react\";\nimport Network from \"../../convts/network/Network\";\nimport Layer from \"../../convts/layer/Layer\";\n\nconst DisplayLayer = ({ layer }: { layer: Layer }) => {\n  return (\n    <div>\n      <div\n        className={\n          \"px-4 p-2 m-4 max-w-sm mx-auto bg-gray-800 rounded-xl shadow-md flex items-center space-x-4\"\n        }\n      >\n        {layer.name()}{\" \"}\n        {layer.getInputSize() && layer.getOutputSize()\n          ? ` (${layer.getInputSize()}, ${layer.getOutputSize()})`\n          : \"\"}\n      </div>\n    </div>\n  );\n};\n\nconst Layers = ({ network }: { network: Network }) => {\n  return (\n    <section>\n      <h1 className={\"text-3xl\"}>Layers</h1>\n      {network.layers.map((l, i) => (\n        <DisplayLayer key={`layer_${i}`} layer={l} />\n      ))}\n    </section>\n  );\n};\n\nconst DisplayNetwork = ({ network }: { network: Network }) => {\n  return (\n    <div>\n      <Layers network={network} />\n    </div>\n  );\n};\n\nexport default DisplayNetwork;\n","\nexport type Activation = (input: number[][]) => number[][];\n\nexport const Relu: Activation = (input: number[][]) => {\n    return input.map((i1) => i1.map((i2) => {\n        return i2 > 0 ? i2 : 0;\n    }))\n}\n\nexport const ReluPrime: Activation = (input: number[][]) => {\n    return input.map((i1) => i1.map((i2) => {\n        return i2 > 0 ? 1 : 0;\n    }))\n}\n\nexport const LeakyRelu: Activation = (input: number[][]) => {\n    return input.map((i1) => i1.map((i2) => {\n        return i2 > 0 ? i2 : i2 * 0.01;\n    }))\n}\n\nexport const LeakyReluPrime: Activation = (input: number[][]) => {\n    return input.map((i1) => i1.map((i2) => {\n        return i2 > 0 ? 1 : 0.01;\n    }))\n}","// https://towardsdatascience.com/linear-algebra-basics-dot-product-and-matrix-multiplication-2a7624942810\nexport const dot = (a: number[][], b: number[][]): number[][] => {\n\n  // Edge cases that should be moved into algorithm \n  if (a.length === 1 && a[0].length === 1 && b.length === 1) {\n    return b.map((b1) => b1.map((b2) => b2 * a[0][0]))\n  }\n\n  if (a.length === 1 && a[0].length > 1 && b.length === a[0].length) {\n    return [Array.from(Array(b[0].length).keys()).map((_, i) => {\n      return a[0].map((_, j) => a[0][j] * b[j][i]).reduce((acc,v2) => acc + v2, 0);\n    })];\n  }\n\n  \n  if (a[0].length === 1 && b.length === 1) {\n    return a.map((a1, i1) => {\n      return b[0].map((_, i2) => {\n        return a[i1][0] * b[0][i2];\n      }).filter((n) => !isNaN(n));\n    });  \n  }\n\n  return a.map((a1, i1) => {\n    return a.map((_, i2) => {\n      return Array.from(Array(a1.length).keys()).reduce((acc, q) => {\n        //console.log(`a[${i1}][${q}] * b[${q}][${i2}]`)\n        return acc + a[i1][q] * b[q][i2];\n      }, 0);\n\n      //return a[i1][i2] * b[i2][i1];\n    }).filter((n) => !isNaN(n));\n  });\n};\nexport const multiply = (a: number[][], b: number | number[][]): number[][] => {\n  if (typeof b === \"number\") {\n    return a.map((_, i) => a[i].map((_, j) => a[i][j] * b));\n  }\n  if (a.length === b.length) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] * b[i][j];\n      })\n      );\n    } else if (a.length === 1) {\n      return b.map((_, i) =>\n      b[0].map((_, j) => {\n        return a[0][j] * b[i][j];\n      })\n      );\n    } else if (b.length === 1) {\n      return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] * b[0][j];\n      })\n    );\n  }\n\n  throw Error(`Dimentions didn't match. a=${a} b=${b}`);\n};\n\nexport const divide = (a: number[][], b: number | number[][]): number[][] => {\n  if (typeof b === \"number\") {\n    return a.map((_, i) => a[i].map((_, j) => a[i][j] / b));\n  }\n  if (a.length === b.length) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] / b[i][j];\n      })\n    );\n  } else if (a.length === 1) {\n    return b.map((_, i) =>\n      b[0].map((_, j) => {\n        return a[0][j] / b[i][j];\n      })\n    );\n  } else if (b.length === 1) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] / b[0][j];\n      })\n    );\n  }\n\n  throw Error(`Dimentions didn't match. a=${a} b=${b}`);\n};\n\nexport const add = (a: number[][], b: number[][]): number[][] => {\n  if (a.length === b.length) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] + b[i][j];\n      })\n    );\n  } else if (a.length === 1) {\n    return b.map((_, i) =>\n      b[0].map((_, j) => {\n        return a[0][j] + b[i][j];\n      })\n    );\n  } else if (b.length === 1) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] + b[0][j];\n      })\n    );\n  }\n\n  throw Error(`Dimentions didn't match. a=${a} b=${b}`);\n};\n\nexport const subtract = (a: number[][], b: number[][]): number[][] => {\n  if (a.length === b.length) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] - b[i][j];\n      })\n    );\n  } else if (a.length === 1) {\n    return b.map((_, i) =>\n      b[0].map((_, j) => {\n        return a[0][j] - b[i][j];\n      })\n    );\n  } else if (b.length === 1) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] - b[0][j];\n      })\n    );\n  }\n\n  throw Error(`Dimentions didn't match. a=${a} b=${b}`);\n};\n\n/**\n * Transpose two dim array. \n * This flips the matrix over its diagonal.\n * It does this by switching the row and column indices.\n * https://en.wikipedia.org/wiki/Transpose\n * https://numpy.org/doc/stable/reference/generated/numpy.transpose.html#numpy.transpose \n */\nexport const transpose = (array: number[][]): number[][] => {\n  return array[0].map((_, columnIndex) => array.map((row) => row[columnIndex]));\n};\n","import { Activation } from \"../activations/activations\";\nimport { multiply } from \"../math/math\";\nimport { NeuronListener, NeuronResult } from \"../recorder/NeuronListener\";\nimport Layer from \"./Layer\";\n\nclass ActivationLayer implements Layer {\n  activation;\n  activationPrime;\n  input: number[][] = [];\n  output : number[][] = [];\n  index: number;\n  neuronListener: NeuronListener;\n  constructor(index: number, activation: Activation, activationPrime: Activation, neuronListener: NeuronListener) {\n    this.activation = activation;\n    this.activationPrime = activationPrime;\n    this.index = index;\n    this.neuronListener = neuronListener;\n  }\n\n  name(): string {\n    return \"Activation\"\n  }\n\n  getInputSize(): number | undefined {\n    return undefined;\n  }\n\n  getOutputSize(): number | undefined {\n    return undefined;\n  }\n\n  forwardPropagation(input: number[][]): number[][] {\n    this.input = input;\n    this.output = this.activation(input);\n    if (this.neuronListener) {\n      this.neuronListener.recordNeurons(this.index, {layerName: \"Activation\", result: this.output, inputSize: input[0].length, outputSize: this.output[0].length} as NeuronResult)\n    }\n    return this.output;\n  }\n  backPropagation(outputError: number[][], learningRate: number): number[][] {\n      //console.log(\"Activation layer: outputError[\",outputError,\"], input[\",this.input,\"], activationPrime[\" +this.activationPrime(this.input) + \"], multiplied[\" + multiply(this.activationPrime(this.input), outputError) + \"]\" )\n    return multiply(this.activationPrime(this.input), outputError);\n  }\n}\n\nexport default ActivationLayer;\n","/**\n * Creates a 2 dim matrix of random weights to be\n * used as initial weights for layers.\n * @param d0 length of dim0\n * @param d1 length of dim1\n */\nexport const createRandomWeights = (dim0: number, dim1: number): number[][] => {\n  return Array.from(Array(dim0).keys()).map((_) => {\n    return Array.from(Array(dim1).keys()).map((_) => {\n      return Math.random() - 0.5;\n    });\n  });\n};\n","import { logger } from \"../log/Logger\";\nimport { add, dot, multiply, subtract, transpose } from \"../math/math\";\nimport { NeuronListener, NeuronResult } from \"../recorder/NeuronListener\";\nimport { createRandomWeights } from \"../weight/weight\";\nimport Layer from \"./Layer\";\n\nclass ConnectedLayer implements Layer {\n  weight: number[][];\n  bias: number[][];\n  input: number[][] = [];\n  inputSize: number;\n  outputSize: number;\n  index: number;\n  neuronListener?: NeuronListener\n  constructor(index: number, inputSize: number, outputSize: number, neuronListener?: NeuronListener) {\n    this.index = index;\n    this.inputSize = inputSize;\n    this.outputSize = outputSize;\n    this.weight = createRandomWeights(inputSize, outputSize);\n    this.bias = createRandomWeights(1, outputSize);\n    this.neuronListener = neuronListener\n  }\n\n  getInputSize(): number {\n    return this.inputSize;\n  }\n\n  getOutputSize(): number {\n    return this.outputSize;\n  }\n\n  name(): string {\n    return \"Connected\";\n  }\n\n  forwardPropagation(input: number[][]): number[][] {\n    this.input = input;\n    const t = add(dot(input, this.weight), this.bias);\n    if (this.neuronListener) {\n      this.neuronListener.recordNeurons(this.index, {layerName: \"Connected\", result: t, inputSize: this.inputSize, outputSize: this.outputSize}  as NeuronResult)\n    }\n    return t;\n  }\n  backPropagation(outputError: number[][], learningRate: number): number[][] {\n    const inputError = dot(outputError, transpose(this.weight));\n    const weightError = dot(transpose(this.input), outputError);\n    //console.log(\"CONNECTED LAYER - weights[\", this.weight,\"], \",\"outputError[\", outputError,\"], inputError[\",inputError,\"], weightError[\",weightError,\"]\");\n    this.weight = subtract(this.weight, multiply(weightError, learningRate));\n    this.bias = subtract(this.bias, multiply(outputError, learningRate));\n\n    return inputError;\n  }\n}\n\nexport default ConnectedLayer;\n","import { divide, multiply, subtract } from \"../math/math\";\n\nexport type LossFunction = (expected: number[][], predicted: number[][]) => number;\nexport type LossPrime = (expected: number[][], predicted: number[][]) => number[][];\n\nexport interface Loss {\n    loss: LossFunction;\n    lossPrime: LossPrime;\n}\n\nexport const meanSquaredError: LossFunction = (\n  expected: number[][],\n  predicted: number[][]\n) => {\n  let count = 0;\n  const value = subtract(expected, predicted)\n    .map((x1) => {\n      return x1.map((x2) => {\n        count += 1;\n        return Math.pow(x2, 2);\n      });\n    })\n    .reduce((acc, v) => {\n      return (\n        acc +\n        v.reduce((acc2, v2) => {\n          return acc2 + v2;\n        }, 0)\n      );\n    }, 0);\n  return value / count;\n};\n\nconst countElements = (n: number[][]) => {\n  return n.reduce((acc, v) => acc + v.length, 0);\n};\n\nexport const meanSquaredErrorPrime: LossPrime = (\n  expected: number[][],\n  predicted: number[][]\n) => {\n  let count = countElements(expected);\n  return multiply(divide(subtract(predicted, expected), count), 2);\n};\n\nexport const Mse: Loss = {\n    loss: meanSquaredError,\n    lossPrime: meanSquaredErrorPrime,\n}\n","export const logger = require('pino')()","import React from \"react\";\nimport Layer from \"../layer/Layer\";\nimport { logger } from \"../log/Logger\";\nimport { Loss } from \"../loss/loss\";\nimport { NeuronListener } from \"../recorder/NeuronListener\";\n\nclass Network {\n  layers: Layer[];\n  loss: Loss;\n  learningRate: number = 0.1;\n  private constructor(layers: Layer[], loss: Loss) {\n    this.layers = layers;\n    this.loss = loss;\n  }\n\n  public static create(layers: Layer[], loss: Loss): Network {\n    return new Network(layers, loss);\n  }\n\n  public predict(data: number[][]) {\n    return this.forwardPropagate(data);\n  }\n\n  public fit(\n    trainingData: number[][][],\n    categories: number[][][],\n    epochs: number\n  ) {\n    let lastEpochError = -1;\n    for (let epoch = 1; epoch <= epochs; epoch++) {\n      const err = trainingData\n        .map((x, i) => {\n          const output = this.forwardPropagate(x);\n          logger.debug({\"Expected\": categories[i], \"Predicted\": output})\n          this.backPropagate(categories[i], output);\n          return this.loss.loss(categories[i], output);\n        })\n        .reduce((acc, v) => acc + v, 0);\n\n      \n      const error = err / trainingData.length;\n      logger.info(\n        `Epoch ${epoch}/${epochs} error=${error}`\n      );\n      lastEpochError=error;\n    }\n    return lastEpochError\n  }\n\n  private backPropagate(expected: number[][], predicted: number[][]) {\n    let error = this.loss.lossPrime(expected, predicted);\n    logger.debug({\"LOSS PRIME \": error})\n    for (var i = this.layers.length - 1; i >= 0; i--) {\n      error = this.layers[i].backPropagation(error, this.learningRate);\n    }\n  }\n\n  private forwardPropagate(data: number[][]) {\n    return this.layers.reduce((output, layer) => {\n      return layer.forwardPropagation(output);\n    }, data);\n  }\n\n  \n}\n\nexport default Network;\n","\nexport interface NeuronResult {\n    inputSize: number;\n    outputSize: number;\n    layerName: string;\n    result: number[][];\n}\n\nexport class NeuronListener {\n\n    callback: (index: number, input: any) => void\n    record: boolean = false\n    lastUpdate: number = Date.now();\n    result: {[_: string]: NeuronResult} = {}\n\n    constructor(callback: (index: number, input: any) => void) {\n      this.callback = callback\n    }\n\n    startRecording() {\n        this.record = true\n    }\n\n    stopRecording() {\n        this.record = false\n    }\n\n    recordNeurons(index: number, input: any) {\n        if (this.record) {\n            this.lastUpdate = Date.now();\n            this.callback(index, input)\n            this.result[`${index}`] = input\n        }\n    }\n  }","import React from \"react\";\n\nconst Neuron = ({ probability }: { probability: number }) => {\n  return (\n    <div\n      className={`flex justify-center items-center m-1 w-12 h-12 ${\n        probability > 0.1 ? \"bg-blue-600\" : \"bg-gray-500\"\n      } bg-opacity-50 rounded-full border-red-700`}\n    >\n      {probability.toFixed(2)}\n    </div>\n  );\n};\n\nexport default Neuron;\n","import React, { useEffect, useState } from \"react\";\nimport {\n  NeuronListener,\n  NeuronResult,\n} from \"../../convts/recorder/NeuronListener\";\nimport Neuron from \"./Neuron\";\n\nconst LayerSection = ({ neuron }: { neuron: NeuronResult }) => {\n  return (\n    <div className={\"bg-gray-800 rounded-md max-w-xl m-2 p-5 w-full\"}>\n      <div className={\"flex items-center\"}>\n          <div className={\"flex-grow\"}>\n        <div className={\"text-xl\"}>{neuron.layerName}</div>\n        <div className={\"text opacity-70\"}>Input size: {neuron.inputSize}</div>\n        <div className={\"text  opacity-70\"}>Output size: {neuron.outputSize}</div>\n              </div>\n        <div  className={\"flex justify-items-center flex-grow\"}>\n          {neuron.result[0].map((nn) => (\n            <Neuron probability={nn} />\n          ))}\n        </div>\n      </div>\n    </div>\n  );\n};\n\nconst NeuralRenderer = ({\n  lastUpdate,\n  neuronListener,\n}: {\n  lastUpdate: number;\n  neuronListener: NeuronListener;\n}) => {\n  return (\n    <div className=\"flex flex-col items-center\">\n      <h2 className=\"text-3xl md:text-4xl font-medium mb-2\">\n        Network visualization\n      </h2>\n\n      {Object.values(neuronListener.result).map((n) => (\n        <LayerSection neuron={n} />\n      ))}\n    </div>\n  );\n};\n\nexport default NeuralRenderer;\n","import React, { useEffect, useState } from \"react\";\nimport logo from \"./logo.svg\";\nimport \"./App.css\";\nimport DisplayNetwork from \"./components/network/DisplayNetwork\";\nimport { createSimpleNetwork } from \"./convts/network/networks\";\nimport Network from \"./convts/network/Network\";\nimport { NeuronListener } from \"./convts/recorder/NeuronListener\";\nimport Neuron from \"./components/network/Neuron\";\nimport NeuralRenderer from \"./components/network/NeuralRenderer\";\n\n\n\n\n\nfunction App() {\n  const [lastUpdate, setLastUpdate] = useState(Date.now());\n  const [neuronListener, setNeuronListener] = useState<NeuronListener>(\n    new NeuronListener((i, ii) => console.log(ii))\n  );\n  const [network, setNetwork] = useState<Network>(\n    createSimpleNetwork(neuronListener)\n  );\n  const [lastEpochError, setLastEpochError] = useState<number | undefined>(\n    undefined\n  );\n  const trainingData = [[[0, 0]], [[0, 1]], [[1, 0]], [[1, 1]]];\n  const categories = [[[0]], [[1]], [[1]], [[0]]];\n\n  return (\n    <div className=\"min-h-screen bg-gray-900 text-white\">\n      <main>\n        <DisplayNetwork network={network} />\n        <button\n          onClick={() => {\n            setLastEpochError(network.fit(trainingData, categories, 1000));\n            neuronListener.startRecording();\n          }}\n          className=\"bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded-full\"\n        >\n          Create and train\n        </button>\n        {lastEpochError && <p>Error after last epoch: {lastEpochError}</p>}\n        {lastEpochError && (\n          <p\n            onClick={() => {\n              network.predict([[1, 0]]);\n              setLastUpdate(neuronListener.lastUpdate);\n            }}\n          >\n            Testing 1,0\n          </p>\n        )}\n        {lastEpochError && (\n          <p\n            onClick={() => {\n              network.predict([[0, 0]]);\n              setLastUpdate(neuronListener.lastUpdate);\n            }}\n          >\n            Testing 0,0\n          </p>\n        )}\n        {lastEpochError && (\n          <p\n            onClick={() => {\n              network.predict([[0, 1]]);\n              setLastUpdate(neuronListener.lastUpdate);\n            }}\n          >\n            Testing 0,1\n          </p>\n        )}\n        {lastEpochError && (\n          <p\n            onClick={() => {\n              network.predict([[1, 1]]);\n              setLastUpdate(neuronListener.lastUpdate);\n            }}\n          >\n            Testing 1,1\n          </p>\n        )}\n        <NeuralRenderer\n          lastUpdate={lastUpdate}\n          neuronListener={neuronListener}\n        />\n        {/* {lastEpochError && <p>Testing 0,1: {network.predict([[0,1]])}</p>}\n        {lastEpochError && <p>Testing 1,1: {network.predict([[1,1]])}</p>}\n        {lastEpochError && <p>Testing 0,1: {network.predict([[1,0]])}</p>} */}\n      </main>\n    </div>\n  );\n}\n\nexport default App;\n","import { LeakyRelu, LeakyReluPrime } from \"../activations/activations\";\nimport ActivationLayer from \"../layer/ActivationLayer\";\nimport ConnectedLayer from \"../layer/ConnectedLayer\";\nimport { Mse } from \"../loss/loss\";\nimport { NeuronListener } from \"../recorder/NeuronListener\";\nimport Network from \"./Network\";\n\n\nexport const createSimpleNetwork = (neuronListener: NeuronListener) => {\n    return Network.create(\n        [\n            new ConnectedLayer(1, 2,3, neuronListener),\n            new ActivationLayer(2, LeakyRelu,LeakyReluPrime, neuronListener),\n            new ConnectedLayer(3, 3,1, neuronListener),\n            new ActivationLayer(4, LeakyRelu,LeakyReluPrime, neuronListener)\n        ], \n        Mse\n    );\n}","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}