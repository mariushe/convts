{"version":3,"sources":["components/network/DisplayNetwork.tsx","convts/activations/activations.ts","convts/math/math.ts","convts/layer/ActivationLayer.ts","convts/weight/weight.ts","convts/layer/ConnectedLayer.ts","convts/loss/loss.ts","convts/log/Logger.ts","convts/network/Network.ts","App.tsx","convts/network/networks.ts","reportWebVitals.ts","index.tsx"],"names":["DisplayLayer","layer","className","name","getInputSize","getOutputSize","Layers","network","layers","map","l","i","DisplayNetwork","LeakyRelu","input","i1","i2","LeakyReluPrime","dot","a","b","length","b1","b2","Array","from","keys","_","j","reduce","acc","v2","a1","filter","n","isNaN","q","multiply","Error","subtract","transpose","array","columnIndex","row","ActivationLayer","activation","activationPrime","output","this","outputError","learningRate","createRandomWeights","dim0","dim1","Math","random","ConnectedLayer","inputSize","outputSize","weight","bias","add","inputError","weightError","Mse","loss","expected","predicted","count","x1","x2","pow","v","acc2","lossPrime","divide","logger","require","Network","data","forwardPropagate","trainingData","categories","epochs","lastEpochError","epoch","error","x","debug","backPropagate","info","backPropagation","forwardPropagation","App","useState","create","undefined","setLastEpochError","fit","onClick","predict","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"oNAIMA,EAAe,SAAC,GAAiC,IAA/BC,EAA8B,EAA9BA,MACtB,OACE,8BACE,sBACEC,UACE,6FAFJ,UAKGD,EAAME,OAAQ,IACdF,EAAMG,gBAAkBH,EAAMI,gBAA9B,YACQJ,EAAMG,eADd,aACiCH,EAAMI,gBADvC,KAEG,SAMNC,EAAS,SAAC,GAAuC,IAArCC,EAAoC,EAApCA,QAChB,OACE,oCACE,oBAAIL,UAAW,WAAf,oBACCK,EAAQC,OAAOC,KAAI,SAACC,EAAGC,GAAJ,OAClB,cAAC,EAAD,CAAiCV,MAAOS,GAAxC,gBAA4BC,WAcrBC,EARQ,SAAC,GAAuC,IAArCL,EAAoC,EAApCA,QACxB,OACE,8BACE,cAAC,EAAD,CAAQA,QAASA,OCpBVM,EAAwB,SAACC,GAClC,OAAOA,EAAML,KAAI,SAACM,GAAD,OAAQA,EAAGN,KAAI,SAACO,GAC7B,OAAOA,EAAK,EAAIA,EAAU,IAALA,SAIhBC,EAA6B,SAACH,GACvC,OAAOA,EAAML,KAAI,SAACM,GAAD,OAAQA,EAAGN,KAAI,SAACO,GAC7B,OAAOA,EAAK,EAAI,EAAI,W,cCtBfE,EAAM,SAACC,EAAeC,GAGjC,OAAiB,IAAbD,EAAEE,QAAgC,IAAhBF,EAAE,GAAGE,QAA6B,IAAbD,EAAEC,OACpCD,EAAEX,KAAI,SAACa,GAAD,OAAQA,EAAGb,KAAI,SAACc,GAAD,OAAQA,EAAKJ,EAAE,GAAG,SAG/B,IAAbA,EAAEE,QAAgBF,EAAE,GAAGE,OAAS,GAAKD,EAAEC,SAAWF,EAAE,GAAGE,OAClD,CAACG,MAAMC,KAAKD,MAAMJ,EAAE,GAAGC,QAAQK,QAAQjB,KAAI,SAACkB,EAAGhB,GACpD,OAAOQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GAAJ,OAAUT,EAAE,GAAGS,GAAKR,EAAEQ,GAAGjB,MAAIkB,QAAO,SAACC,EAAIC,GAAL,OAAYD,EAAMC,IAAI,OAK1D,IAAhBZ,EAAE,GAAGE,QAA6B,IAAbD,EAAEC,OAClBF,EAAEV,KAAI,SAACuB,EAAIjB,GAChB,OAAOK,EAAE,GAAGX,KAAI,SAACkB,EAAGX,GAClB,OAAOG,EAAEJ,GAAI,GAAKK,EAAE,GAAGJ,MACtBiB,QAAO,SAACC,GAAD,OAAQC,MAAMD,SAIrBf,EAAEV,KAAI,SAACuB,EAAIjB,GAChB,OAAOI,EAAEV,KAAI,SAACkB,EAAGX,GACf,OAAOQ,MAAMC,KAAKD,MAAMQ,EAAGX,QAAQK,QAAQG,QAAO,SAACC,EAAKM,GAEtD,OAAON,EAAMX,EAAEJ,GAAIqB,GAAKhB,EAAEgB,GAAGpB,KAC5B,MAGFiB,QAAO,SAACC,GAAD,OAAQC,MAAMD,UAGfG,EAAW,SAAClB,EAAeC,GACtC,GAAiB,kBAANA,EACT,OAAOD,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OAAUQ,EAAER,GAAGF,KAAI,SAACkB,EAAGC,GAAJ,OAAUT,EAAER,GAAGiB,GAAKR,QAEtD,GAAID,EAAEE,SAAWD,EAAEC,OACjB,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAET,GAAGiB,SAGnB,GAAiB,IAAbT,EAAEE,OACX,OAAOD,EAAEX,KAAI,SAACkB,EAAGhB,GAAJ,OACbS,EAAE,GAAGX,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAE,GAAGS,GAAKR,EAAET,GAAGiB,SAGnB,GAAiB,IAAbR,EAAEC,OACX,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACbQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAE,GAAGQ,SAK5B,MAAMU,MAAM,8BAAD,OAA+BnB,EAA/B,cAAsCC,KAsDtCmB,EAAW,SAACpB,EAAeC,GACtC,GAAID,EAAEE,SAAWD,EAAEC,OACjB,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbT,EAAEE,OACX,OAAOD,EAAEX,KAAI,SAACkB,EAAGhB,GAAJ,OACXS,EAAE,GAAGX,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAE,GAAGS,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbR,EAAEC,OACX,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAE,GAAGQ,SAK5B,MAAMU,MAAM,8BAAD,OAA+BnB,EAA/B,cAAsCC,KAUtCoB,EAAY,SAACC,GACxB,OAAOA,EAAM,GAAGhC,KAAI,SAACkB,EAAGe,GAAJ,OAAoBD,EAAMhC,KAAI,SAACkC,GAAD,OAASA,EAAID,UC3GlDE,E,WA5Bb,WAAYC,EAAwBC,GAA8B,yBAJlED,gBAIiE,OAHjEC,qBAGiE,OAFjEhC,MAAoB,GAE6C,KADjEiC,OAAsB,GAEpBC,KAAKH,WAAaA,EAClBG,KAAKF,gBAAkBA,E,wCAGzB,WACE,MAAO,e,0BAGT,c,2BAIA,c,gCAIA,SAAmBhC,GAGjB,OAFAkC,KAAKlC,MAAQA,EACbkC,KAAKD,OAASC,KAAKH,WAAW/B,GACvBkC,KAAKD,S,6BAEd,SAAgBE,EAAyBC,GAEvC,OAAOb,EAASW,KAAKF,gBAAgBE,KAAKlC,OAAQmC,O,KC3BzCE,EAAsB,SAACC,EAAcC,GAChD,OAAO7B,MAAMC,KAAKD,MAAM4B,GAAM1B,QAAQjB,KAAI,SAACkB,GACzC,OAAOH,MAAMC,KAAKD,MAAM6B,GAAM3B,QAAQjB,KAAI,SAACkB,GACzC,OAAO2B,KAAKC,SAAW,UCoCdC,E,WAnCb,WAAYC,EAAmBC,GAAqB,yBALpDC,YAKmD,OAJnDC,UAImD,OAHnD9C,MAAoB,GAG+B,KAFnD2C,eAEmD,OADnDC,gBACmD,EACjDV,KAAKS,UAAYA,EACjBT,KAAKU,WAAaA,EAClBV,KAAKW,OAASR,EAAoBM,EAAWC,GAC7CV,KAAKY,KAAOT,EAAoB,EAAGO,G,gDAGrC,WACE,OAAOV,KAAKS,Y,2BAGd,WACE,OAAOT,KAAKU,a,kBAGd,WACE,MAAO,c,gCAGT,SAAmB5C,GAGjB,OAFAkC,KAAKlC,MAAQA,EH0DE,SAACK,EAAeC,GACjC,GAAID,EAAEE,SAAWD,EAAEC,OACjB,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbT,EAAEE,OACX,OAAOD,EAAEX,KAAI,SAACkB,EAAGhB,GAAJ,OACXS,EAAE,GAAGX,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAE,GAAGS,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbR,EAAEC,OACX,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAE,GAAGQ,SAK5B,MAAMU,MAAM,8BAAD,OAA+BnB,EAA/B,cAAsCC,IG9ErCyC,CAAI3C,EAAIJ,EAAOkC,KAAKW,QAASX,KAAKY,Q,6BAG9C,SAAgBX,EAAyBC,GACvC,IAAMY,EAAa5C,EAAI+B,EAAaT,EAAUQ,KAAKW,SAC7CI,EAAc7C,EAAIsB,EAAUQ,KAAKlC,OAAQmC,GAK/C,OAHAD,KAAKW,OAASpB,EAASS,KAAKW,OAAQtB,EAAS0B,EAAab,IAC1DF,KAAKY,KAAOrB,EAASS,KAAKY,KAAMvB,EAASY,EAAaC,IAE/CY,M,KCIEE,EAAY,CACrBC,KApC0C,SAC5CC,EACAC,GAEA,IAAIC,EAAQ,EAgBZ,OAfc7B,EAAS2B,EAAUC,GAC9B1D,KAAI,SAAC4D,GACJ,OAAOA,EAAG5D,KAAI,SAAC6D,GAEb,OADAF,GAAS,EACFd,KAAKiB,IAAID,EAAI,SAGvBzC,QAAO,SAACC,EAAK0C,GACZ,OACE1C,EACA0C,EAAE3C,QAAO,SAAC4C,EAAM1C,GACd,OAAO0C,EAAO1C,IACb,KAEJ,GACUqC,GAiBbM,UAV4C,SAC9CR,EACAC,GAEA,IAAIC,EAAsBF,EAPjBrC,QAAO,SAACC,EAAK0C,GAAN,OAAY1C,EAAM0C,EAAEnD,SAAQ,GAQ5C,OAAOgB,EJmBa,SAAClB,EAAeC,GACpC,GAAiB,kBAANA,EACT,OAAOD,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OAAUQ,EAAER,GAAGF,KAAI,SAACkB,EAAGC,GAAJ,OAAUT,EAAER,GAAGiB,GAAKR,QAEtD,GAAID,EAAEE,SAAWD,EAAEC,OACjB,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbT,EAAEE,OACX,OAAOD,EAAEX,KAAI,SAACkB,EAAGhB,GAAJ,OACXS,EAAE,GAAGX,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAE,GAAGS,GAAKR,EAAET,GAAGiB,SAGrB,GAAiB,IAAbR,EAAEC,OACX,OAAOF,EAAEV,KAAI,SAACkB,EAAGhB,GAAJ,OACXQ,EAAE,GAAGV,KAAI,SAACkB,EAAGC,GACX,OAAOT,EAAER,GAAGiB,GAAKR,EAAE,GAAGQ,SAK5B,MAAMU,MAAM,8BAAD,OAA+BnB,EAA/B,cAAsCC,II3CjCuD,CAAOpC,EAAS4B,EAAWD,GAAWE,GAAQ,KC1CnDQ,EAASC,EAAQ,GAARA,GCiEPC,E,WAxDb,WAAoBtE,EAAiByD,GAAa,yBAHlDzD,YAGiD,OAFjDyD,UAEiD,OADjDf,aAAuB,GAErBF,KAAKxC,OAASA,EACdwC,KAAKiB,KAAOA,E,2CAOd,SAAec,GACb,OAAO/B,KAAKgC,iBAAiBD,K,iBAG/B,SACEE,EACAC,EACAC,GAGA,IAFC,IAAD,OACIC,GAAkB,EACbC,EAAQ,EAAGA,GAASF,EAAQE,IAAS,CAC5C,IAUMC,EAVML,EACTxE,KAAI,SAAC8E,EAAG5E,GACP,IAAMoC,EAAS,EAAKiC,iBAAiBO,GAGrC,OAFAX,EAAOY,MAAM,CAAC,SAAYN,EAAWvE,GAAI,UAAaoC,IACtD,EAAK0C,cAAcP,EAAWvE,GAAIoC,GAC3B,EAAKkB,KAAKA,KAAKiB,EAAWvE,GAAIoC,MAEtClB,QAAO,SAACC,EAAK0C,GAAN,OAAY1C,EAAM0C,IAAG,GAGXS,EAAa5D,OACjCuD,EAAOc,KAAP,gBACWL,EADX,YACoBF,EADpB,kBACoCG,IAEpCF,EAAeE,EAEjB,OAAOF,I,2BAGT,SAAsBlB,EAAsBC,GAC1C,IAAImB,EAAQtC,KAAKiB,KAAKS,UAAUR,EAAUC,GAC1CS,EAAOY,MAAM,CAAC,cAAeF,IAC7B,IAAK,IAAI3E,EAAIqC,KAAKxC,OAAOa,OAAS,EAAGV,GAAK,EAAGA,IAC3C2E,EAAQtC,KAAKxC,OAAOG,GAAGgF,gBAAgBL,EAAOtC,KAAKE,gB,8BAIvD,SAAyB6B,GACvB,OAAO/B,KAAKxC,OAAOqB,QAAO,SAACkB,EAAQ9C,GACjC,OAAOA,EAAM2F,mBAAmB7C,KAC/BgC,M,qBA7CL,SAAqBvE,EAAiByD,GACpC,OAAO,IAAIa,EAAQtE,EAAQyD,O,KCuBhB4B,MA/Bf,WAAgB,IAAD,EACiBC,mBCArBhB,EAAQiB,OACX,CACI,IAAIvC,EAAe,EAAE,GACrB,IAAIZ,EAAgB/B,EAAUI,GAC9B,IAAIuC,EAAe,EAAE,GACrB,IAAIZ,EAAgB/B,EAAUI,IAElC+C,IDRO,mBACNzD,EADM,aAE+BuF,wBAA6BE,IAF5D,mBAENZ,EAFM,KAEUa,EAFV,KAGPhB,EAAe,CAAC,CAAC,CAAC,EAAG,IAAK,CAAC,CAAC,EAAG,IAAK,CAAC,CAAC,EAAG,IAAK,CAAC,CAAC,EAAG,KACnDC,EAAa,CAAC,CAAC,CAAC,IAAK,CAAC,CAAC,IAAK,CAAC,CAAC,IAAK,CAAC,CAAC,KAI3C,OAFA3E,EAAQ2F,IAAIjB,EAAcC,EAAY,KAGpC,qBAAKhF,UAAU,sCAAf,SACE,iCACE,cAAC,EAAD,CAAgBK,QAASA,IACzB,wBACA4F,QAAS,WACPF,EAAkB1F,EAAQ2F,IAAIjB,EAAcC,EAAY,OAG1DhF,UAAU,4EALV,8BAQCkF,GAAkB,yDAA4BA,KAC9CA,GAAkB,8CAAiB7E,EAAQ6F,QAAQ,CAAC,CAAC,EAAE,QACvDhB,GAAkB,8CAAiB7E,EAAQ6F,QAAQ,CAAC,CAAC,EAAE,QACvDhB,GAAkB,8CAAiB7E,EAAQ6F,QAAQ,CAAC,CAAC,EAAE,QACvDhB,GAAkB,8CAAiB7E,EAAQ6F,QAAQ,CAAC,CAAC,EAAE,cEjBjDC,EAZS,SAACC,GACnBA,GAAeA,aAAuBC,UACxC,6BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCHdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.a46fecb2.chunk.js","sourcesContent":["import React from \"react\";\nimport Network from \"../../convts/network/Network\";\nimport Layer from \"../../convts/layer/Layer\";\n\nconst DisplayLayer = ({ layer }: { layer: Layer }) => {\n  return (\n    <div>\n      <div\n        className={\n          \"px-4 p-2 m-4 max-w-sm mx-auto bg-gray-800 rounded-xl shadow-md flex items-center space-x-4\"\n        }\n      >\n        {layer.name()}{\" \"}\n        {layer.getInputSize() && layer.getOutputSize()\n          ? ` (${layer.getInputSize()}, ${layer.getOutputSize()})`\n          : \"\"}\n      </div>\n    </div>\n  );\n};\n\nconst Layers = ({ network }: { network: Network }) => {\n  return (\n    <section>\n      <h1 className={\"text-3xl\"}>Layers</h1>\n      {network.layers.map((l, i) => (\n        <DisplayLayer key={`layer_${i}`} layer={l} />\n      ))}\n    </section>\n  );\n};\n\nconst DisplayNetwork = ({ network }: { network: Network }) => {\n  return (\n    <div>\n      <Layers network={network} />\n    </div>\n  );\n};\n\nexport default DisplayNetwork;\n","\nexport type Activation = (input: number[][]) => number[][];\n\nexport const Relu: Activation = (input: number[][]) => {\n    return input.map((i1) => i1.map((i2) => {\n        return i2 > 0 ? i2 : 0;\n    }))\n}\n\nexport const ReluPrime: Activation = (input: number[][]) => {\n    return input.map((i1) => i1.map((i2) => {\n        return i2 > 0 ? 1 : 0;\n    }))\n}\n\nexport const LeakyRelu: Activation = (input: number[][]) => {\n    return input.map((i1) => i1.map((i2) => {\n        return i2 > 0 ? i2 : i2 * 0.01;\n    }))\n}\n\nexport const LeakyReluPrime: Activation = (input: number[][]) => {\n    return input.map((i1) => i1.map((i2) => {\n        return i2 > 0 ? 1 : 0.01;\n    }))\n}","// https://towardsdatascience.com/linear-algebra-basics-dot-product-and-matrix-multiplication-2a7624942810\nexport const dot = (a: number[][], b: number[][]): number[][] => {\n\n  // Edge cases that should be moved into algorithm \n  if (a.length === 1 && a[0].length === 1 && b.length === 1) {\n    return b.map((b1) => b1.map((b2) => b2 * a[0][0]))\n  }\n\n  if (a.length === 1 && a[0].length > 1 && b.length === a[0].length) {\n    return [Array.from(Array(b[0].length).keys()).map((_, i) => {\n      return a[0].map((_, j) => a[0][j] * b[j][i]).reduce((acc,v2) => acc + v2, 0);\n    })];\n  }\n\n  \n  if (a[0].length === 1 && b.length === 1) {\n    return a.map((a1, i1) => {\n      return b[0].map((_, i2) => {\n        return a[i1][0] * b[0][i2];\n      }).filter((n) => !isNaN(n));\n    });  \n  }\n\n  return a.map((a1, i1) => {\n    return a.map((_, i2) => {\n      return Array.from(Array(a1.length).keys()).reduce((acc, q) => {\n        //console.log(`a[${i1}][${q}] * b[${q}][${i2}]`)\n        return acc + a[i1][q] * b[q][i2];\n      }, 0);\n\n      //return a[i1][i2] * b[i2][i1];\n    }).filter((n) => !isNaN(n));\n  });\n};\nexport const multiply = (a: number[][], b: number | number[][]): number[][] => {\n  if (typeof b === \"number\") {\n    return a.map((_, i) => a[i].map((_, j) => a[i][j] * b));\n  }\n  if (a.length === b.length) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] * b[i][j];\n      })\n      );\n    } else if (a.length === 1) {\n      return b.map((_, i) =>\n      b[0].map((_, j) => {\n        return a[0][j] * b[i][j];\n      })\n      );\n    } else if (b.length === 1) {\n      return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] * b[0][j];\n      })\n    );\n  }\n\n  throw Error(`Dimentions didn't match. a=${a} b=${b}`);\n};\n\nexport const divide = (a: number[][], b: number | number[][]): number[][] => {\n  if (typeof b === \"number\") {\n    return a.map((_, i) => a[i].map((_, j) => a[i][j] / b));\n  }\n  if (a.length === b.length) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] / b[i][j];\n      })\n    );\n  } else if (a.length === 1) {\n    return b.map((_, i) =>\n      b[0].map((_, j) => {\n        return a[0][j] / b[i][j];\n      })\n    );\n  } else if (b.length === 1) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] / b[0][j];\n      })\n    );\n  }\n\n  throw Error(`Dimentions didn't match. a=${a} b=${b}`);\n};\n\nexport const add = (a: number[][], b: number[][]): number[][] => {\n  if (a.length === b.length) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] + b[i][j];\n      })\n    );\n  } else if (a.length === 1) {\n    return b.map((_, i) =>\n      b[0].map((_, j) => {\n        return a[0][j] + b[i][j];\n      })\n    );\n  } else if (b.length === 1) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] + b[0][j];\n      })\n    );\n  }\n\n  throw Error(`Dimentions didn't match. a=${a} b=${b}`);\n};\n\nexport const subtract = (a: number[][], b: number[][]): number[][] => {\n  if (a.length === b.length) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] - b[i][j];\n      })\n    );\n  } else if (a.length === 1) {\n    return b.map((_, i) =>\n      b[0].map((_, j) => {\n        return a[0][j] - b[i][j];\n      })\n    );\n  } else if (b.length === 1) {\n    return a.map((_, i) =>\n      a[0].map((_, j) => {\n        return a[i][j] - b[0][j];\n      })\n    );\n  }\n\n  throw Error(`Dimentions didn't match. a=${a} b=${b}`);\n};\n\n/**\n * Transpose two dim array. \n * This flips the matrix over its diagonal.\n * It does this by switching the row and column indices.\n * https://en.wikipedia.org/wiki/Transpose\n * https://numpy.org/doc/stable/reference/generated/numpy.transpose.html#numpy.transpose \n */\nexport const transpose = (array: number[][]): number[][] => {\n  return array[0].map((_, columnIndex) => array.map((row) => row[columnIndex]));\n};\n","import { Activation } from \"../activations/activations\";\nimport { multiply } from \"../math/math\";\nimport Layer from \"./Layer\";\n\nclass ActivationLayer implements Layer {\n  activation;\n  activationPrime;\n  input: number[][] = [];\n  output : number[][] = [];\n  constructor(activation: Activation, activationPrime: Activation) {\n    this.activation = activation;\n    this.activationPrime = activationPrime;\n  }\n\n  name(): string {\n    return \"Activation\"\n  }\n\n  getInputSize(): number | undefined {\n    return undefined;\n  }\n\n  getOutputSize(): number | undefined {\n    return undefined;\n  }\n\n  forwardPropagation(input: number[][]): number[][] {\n    this.input = input;\n    this.output = this.activation(input);\n    return this.output;\n  }\n  backPropagation(outputError: number[][], learningRate: number): number[][] {\n      //console.log(\"Activation layer: outputError[\",outputError,\"], input[\",this.input,\"], activationPrime[\" +this.activationPrime(this.input) + \"], multiplied[\" + multiply(this.activationPrime(this.input), outputError) + \"]\" )\n    return multiply(this.activationPrime(this.input), outputError);\n  }\n}\n\nexport default ActivationLayer;\n","/**\n * Creates a 2 dim matrix of random weights to be\n * used as initial weights for layers.\n * @param d0 length of dim0\n * @param d1 length of dim1\n */\nexport const createRandomWeights = (dim0: number, dim1: number): number[][] => {\n  return Array.from(Array(dim0).keys()).map((_) => {\n    return Array.from(Array(dim1).keys()).map((_) => {\n      return Math.random() - 0.5;\n    });\n  });\n};\n","import { add, dot, multiply, subtract, transpose } from \"../math/math\";\nimport { createRandomWeights } from \"../weight/weight\";\nimport Layer from \"./Layer\";\n\nclass ConnectedLayer implements Layer {\n  weight: number[][];\n  bias: number[][];\n  input: number[][] = [];\n  inputSize: number;\n  outputSize: number;\n  constructor(inputSize: number, outputSize: number) {\n    this.inputSize = inputSize;\n    this.outputSize = outputSize;\n    this.weight = createRandomWeights(inputSize, outputSize);\n    this.bias = createRandomWeights(1, outputSize);\n  }\n\n  getInputSize(): number {\n    return this.inputSize;\n  }\n\n  getOutputSize(): number {\n    return this.outputSize;\n  }\n\n  name(): string {\n    return \"Connected\";\n  }\n\n  forwardPropagation(input: number[][]): number[][] {\n    this.input = input;\n    const t = add(dot(input, this.weight), this.bias);\n    return t;\n  }\n  backPropagation(outputError: number[][], learningRate: number): number[][] {\n    const inputError = dot(outputError, transpose(this.weight));\n    const weightError = dot(transpose(this.input), outputError);\n    //console.log(\"CONNECTED LAYER - weights[\", this.weight,\"], \",\"outputError[\", outputError,\"], inputError[\",inputError,\"], weightError[\",weightError,\"]\");\n    this.weight = subtract(this.weight, multiply(weightError, learningRate));\n    this.bias = subtract(this.bias, multiply(outputError, learningRate));\n\n    return inputError;\n  }\n}\n\nexport default ConnectedLayer;\n","import { divide, multiply, subtract } from \"../math/math\";\n\nexport type LossFunction = (expected: number[][], predicted: number[][]) => number;\nexport type LossPrime = (expected: number[][], predicted: number[][]) => number[][];\n\nexport interface Loss {\n    loss: LossFunction;\n    lossPrime: LossPrime;\n}\n\nexport const meanSquaredError: LossFunction = (\n  expected: number[][],\n  predicted: number[][]\n) => {\n  let count = 0;\n  const value = subtract(expected, predicted)\n    .map((x1) => {\n      return x1.map((x2) => {\n        count += 1;\n        return Math.pow(x2, 2);\n      });\n    })\n    .reduce((acc, v) => {\n      return (\n        acc +\n        v.reduce((acc2, v2) => {\n          return acc2 + v2;\n        }, 0)\n      );\n    }, 0);\n  return value / count;\n};\n\nconst countElements = (n: number[][]) => {\n  return n.reduce((acc, v) => acc + v.length, 0);\n};\n\nexport const meanSquaredErrorPrime: LossPrime = (\n  expected: number[][],\n  predicted: number[][]\n) => {\n  let count = countElements(expected);\n  return multiply(divide(subtract(predicted, expected), count), 2);\n};\n\nexport const Mse: Loss = {\n    loss: meanSquaredError,\n    lossPrime: meanSquaredErrorPrime,\n}\n","export const logger = require('pino')()","import React from \"react\";\nimport Layer from \"../layer/Layer\";\nimport { logger } from \"../log/Logger\";\nimport { Loss } from \"../loss/loss\";\n\nclass Network {\n  layers: Layer[];\n  loss: Loss;\n  learningRate: number = 0.1;\n  private constructor(layers: Layer[], loss: Loss) {\n    this.layers = layers;\n    this.loss = loss;\n  }\n\n  public static create(layers: Layer[], loss: Loss): Network {\n    return new Network(layers, loss);\n  }\n\n  public predict(data: number[][]) {\n    return this.forwardPropagate(data);\n  }\n\n  public fit(\n    trainingData: number[][][],\n    categories: number[][][],\n    epochs: number\n  ) {\n    let lastEpochError = -1;\n    for (let epoch = 1; epoch <= epochs; epoch++) {\n      const err = trainingData\n        .map((x, i) => {\n          const output = this.forwardPropagate(x);\n          logger.debug({\"Expected\": categories[i], \"Predicted\": output})\n          this.backPropagate(categories[i], output);\n          return this.loss.loss(categories[i], output);\n        })\n        .reduce((acc, v) => acc + v, 0);\n\n      \n      const error = err / trainingData.length;\n      logger.info(\n        `Epoch ${epoch}/${epochs} error=${error}`\n      );\n      lastEpochError=error;\n    }\n    return lastEpochError\n  }\n\n  private backPropagate(expected: number[][], predicted: number[][]) {\n    let error = this.loss.lossPrime(expected, predicted);\n    logger.debug({\"LOSS PRIME \": error})\n    for (var i = this.layers.length - 1; i >= 0; i--) {\n      error = this.layers[i].backPropagation(error, this.learningRate);\n    }\n  }\n\n  private forwardPropagate(data: number[][]) {\n    return this.layers.reduce((output, layer) => {\n      return layer.forwardPropagation(output);\n    }, data);\n  }\n\n  \n}\n\nexport default Network;\n","import React, { useState } from \"react\";\nimport logo from \"./logo.svg\";\nimport \"./App.css\";\nimport DisplayNetwork from \"./components/network/DisplayNetwork\";\nimport { createSimpleNetwork } from \"./convts/network/networks\";\nimport Network from \"./convts/network/Network\";\n\nfunction App() {\n  const [network, setNetwork] = useState<Network>(createSimpleNetwork());\n  const [lastEpochError, setLastEpochError] = useState<number | undefined>(undefined);\n  const trainingData = [[[0, 0]], [[0, 1]], [[1, 0]], [[1, 1]]];\n  const categories = [[[0]], [[1]], [[1]], [[0]]];\n\n  network.fit(trainingData, categories, 1000);\n\n  return (\n    <div className=\"min-h-screen bg-gray-900 text-white\">\n      <main>\n        <DisplayNetwork network={network} />\n        <button \n        onClick={() => {\n          setLastEpochError(network.fit(trainingData, categories, 1000));\n          \n        }}\n        className=\"bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded-full\">\n          Create and train\n        </button>\n        {lastEpochError && <p>Error after last epoch: {lastEpochError}</p>}\n        {lastEpochError && <p>Testing 0,0: {network.predict([[0,0]])}</p>}\n        {lastEpochError && <p>Testing 0,1: {network.predict([[0,1]])}</p>}\n        {lastEpochError && <p>Testing 1,1: {network.predict([[1,1]])}</p>}\n        {lastEpochError && <p>Testing 0,1: {network.predict([[1,0]])}</p>}\n        \n      </main>\n    </div>\n  );\n}\n\nexport default App;\n","import { LeakyRelu, LeakyReluPrime } from \"../activations/activations\";\nimport ActivationLayer from \"../layer/ActivationLayer\";\nimport ConnectedLayer from \"../layer/ConnectedLayer\";\nimport { Mse } from \"../loss/loss\";\nimport Network from \"./Network\";\n\n\nexport const createSimpleNetwork = () => {\n    return Network.create(\n        [\n            new ConnectedLayer(2,3),\n            new ActivationLayer(LeakyRelu,LeakyReluPrime),\n            new ConnectedLayer(3,1),\n            new ActivationLayer(LeakyRelu,LeakyReluPrime)\n        ], \n        Mse\n    );\n}","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}